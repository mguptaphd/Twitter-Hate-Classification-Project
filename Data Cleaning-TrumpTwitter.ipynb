{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn\n",
    "\n",
    "# NLTK/NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from nltk.collocations import *\n",
    "import gensim\n",
    "\n",
    "# Classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Sampling\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import sklearn.decomposition as decomposition\n",
    "\n",
    "#Visualization\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run custom_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14297</td>\n",
       "      <td>0</td>\n",
       "      <td>retweets @user #nuascannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14016</td>\n",
       "      <td>0</td>\n",
       "      <td>a classic trump follower.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7009</td>\n",
       "      <td>0</td>\n",
       "      <td>in the mixture of emotions, here's a   one fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18926</td>\n",
       "      <td>0</td>\n",
       "      <td>@user the meps bear that travelled to sandy ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28292</td>\n",
       "      <td>0</td>\n",
       "      <td>just because it affected her son?   sonâs ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...\n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...\n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...\n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...\n",
       "4  25845      0  what are your goals? find out here...   #smile...\n",
       "5  14297      0                         retweets @user #nuascannan\n",
       "6  14016      0                          a classic trump follower.\n",
       "7   7009      0  in the mixture of emotions, here's a   one fro...\n",
       "8  18926      0  @user the meps bear that travelled to sandy ho...\n",
       "9  28292      0  just because it affected her son?   sonâs ab..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=pd.read_csv('train-file.csv')\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# # df.to_csv('train-reshuffled.csv')\n",
    "\n",
    "df=pd.read_csv('data/train-reshuffled.csv')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...\n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...\n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...\n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...\n",
       "4  25845      0  what are your goals? find out here...   #smile..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10=df[0:10]\n",
    "df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tidy_tweet'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tidy_tweet'] = df['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tidy_tweet']= df['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_hash_tweet']= df['tidy_tweet'].str.replace(\"#\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>scenes hooligans #engrus spoil #euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>[scenes, hooligans, engrus, spoil, euro]</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, to, be, a...</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, to, be, a...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil bihday #lnic #lnicjustanevilbday #b...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what your goals find here #smile</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>[what, your, goals, find, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>what are your goals find out here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0               scenes hooligans #engrus spoil #euro   \n",
       "1         #gooddyeyoung #yoyoyo super happy movement   \n",
       "2  queen evil bihday #lnic #lnicjustanevilbday #b...   \n",
       "3     might libtard #libtard #sjw #liberal #politics   \n",
       "4                   what your goals find here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0           [scenes, hooligans, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4             [what, your, goals, find, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happi, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happy, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0  sad to see the scenes of hooligans pre engrus ...  \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...  \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...  \n",
       "3  you might be a libtard if libtard sjw liberal ...  \n",
       "4             what are your goals find out here smil  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_tweet'] = df['no_hash_tweet'].apply(lambda x: x.split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>scenes hooligans #engrus spoil #euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>[scenes, hooligans, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>[sad, to, see, the, scene, of, hooligan, pre, ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, to, be, a...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil bihday #lnic #lnicjustanevilbday #b...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, s, bihday, lnic, lnicjustanevilb...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liber, polit]</td>\n",
       "      <td>[you, might, be, a, libtard, if, libtard, sjw,...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what your goals find here #smile</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>[what, your, goals, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>[what, are, your, goal, find, out, here, smile]</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>what are your goals find out here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0               scenes hooligans #engrus spoil #euro   \n",
       "1         #gooddyeyoung #yoyoyo super happy movement   \n",
       "2  queen evil bihday #lnic #lnicjustanevilbday #b...   \n",
       "3     might libtard #libtard #sjw #liberal #politics   \n",
       "4                   what your goals find here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0           [scenes, hooligans, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4             [what, your, goals, find, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happi, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3       [might, libtard, libtard, sjw, liber, polit]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [sad, to, see, the, scene, of, hooligan, pre, ...   \n",
       "1  [gooddyeyoung, yoyoyo, super, happy, to, be, a...   \n",
       "2  [queen, evil, s, bihday, lnic, lnicjustanevilb...   \n",
       "3  [you, might, be, a, libtard, if, libtard, sjw,...   \n",
       "4    [what, are, your, goal, find, out, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0  sad to see the scenes of hooligans pre engrus ...  \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...  \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...  \n",
       "3  you might be a libtard if libtard sjw liberal ...  \n",
       "4             what are your goals find out here smil  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "df['stemmed_tokens'] = df.tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>scenes hooligans #engrus spoil #euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>[scenes, hooligans, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "      <td>sad to see the scenes of hooligans pre engrus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy to be apa of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil bihday #lnic #lnicjustanevilbday #b...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "      <td>queen evil s bihday lnic lnicjustanevilbday bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liber, polit]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "      <td>you might be a libtard if libtard sjw liberal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what your goals find here #smile</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>[what, your, goals, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>what are your goals find out here smile</td>\n",
       "      <td>what are your goals find out here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0               scenes hooligans #engrus spoil #euro   \n",
       "1         #gooddyeyoung #yoyoyo super happy movement   \n",
       "2  queen evil bihday #lnic #lnicjustanevilbday #b...   \n",
       "3     might libtard #libtard #sjw #liberal #politics   \n",
       "4                   what your goals find here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0           [scenes, hooligans, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4             [what, your, goals, find, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happi, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3       [might, libtard, libtard, sjw, liber, polit]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0  sad to see the scenes of hooligans pre engrus ...   \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...   \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...   \n",
       "3  you might be a libtard if libtard sjw liberal ...   \n",
       "4            what are your goals find out here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0  sad to see the scenes of hooligans pre engrus ...  \n",
       "1  gooddyeyoung yoyoyo super happy to be apa of t...  \n",
       "2  queen evil s bihday lnic lnicjustanevilbday bi...  \n",
       "3  you might be a libtard if libtard sjw liberal ...  \n",
       "4             what are your goals find out here smil  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_tokens'] = df.tokenized_tweet.apply(lambda x: [lemmatizer.lemmatize(i) for i in x]) # lemmatizing\n",
    "# [lemmatizer.lemmatize(word) for word in df.no_hash_tweet]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scene'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.stemmed_tokens[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem_tweet'] = [lemmatizer.lemmatize(word) for word in df.no_hash_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem_tweet'] = [stemmer.stem(word) for word in df.no_hash_tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>scenes hooligans #engrus spoil #euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>[scenes, hooligans, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy mov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil bihday #lnic #lnicjustanevilbday #b...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liber, polit]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>might libtard libtard sjw liberal polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what your goals find here #smile</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>[what, your, goals, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>what your goals find here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0               scenes hooligans #engrus spoil #euro   \n",
       "1         #gooddyeyoung #yoyoyo super happy movement   \n",
       "2  queen evil bihday #lnic #lnicjustanevilbday #b...   \n",
       "3     might libtard #libtard #sjw #liberal #politics   \n",
       "4                   what your goals find here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0           [scenes, hooligans, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4             [what, your, goals, find, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happi, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3       [might, libtard, libtard, sjw, liber, polit]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0                 scenes hooligans engrus spoil euro  \n",
       "1                gooddyeyoung yoyoyo super happy mov  \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...  \n",
       "3            might libtard libtard sjw liberal polit  \n",
       "4                     what your goals find here smil  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>scenes hooligans #engrus spoil #euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>[scenes, hooligans, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy mov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil bihday #lnic #lnicjustanevilbday #b...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what your goals find here #smile</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>[what, your, goals, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>what your goals find here smil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14297</td>\n",
       "      <td>0</td>\n",
       "      <td>retweets @user #nuascannan</td>\n",
       "      <td>retweets #nuascannan</td>\n",
       "      <td>retweets nuascannan</td>\n",
       "      <td>[retweets, nuascannan]</td>\n",
       "      <td>[retweet, nuascannan]</td>\n",
       "      <td>[retweets, nuascannan]</td>\n",
       "      <td>retweets nuascannan</td>\n",
       "      <td>retweets nuascannan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "5  14297      0                         retweets @user #nuascannan   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0               scenes hooligans #engrus spoil #euro   \n",
       "1         #gooddyeyoung #yoyoyo super happy movement   \n",
       "2  queen evil bihday #lnic #lnicjustanevilbday #b...   \n",
       "4                   what your goals find here #smile   \n",
       "5                               retweets #nuascannan   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "4                    what your goals find here smile   \n",
       "5                                retweets nuascannan   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0           [scenes, hooligans, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "4             [what, your, goals, find, here, smile]   \n",
       "5                             [retweets, nuascannan]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happi, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "5                              [retweet, nuascannan]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "5                             [retweets, nuascannan]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "4                    what your goals find here smile   \n",
       "5                                retweets nuascannan   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0                 scenes hooligans engrus spoil euro  \n",
       "1                gooddyeyoung yoyoyo super happy mov  \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...  \n",
       "4                     what your goals find here smil  \n",
       "5                                retweets nuascannan  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0=df[df['label']==0]\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liber, polit]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>might libtard libtard sjw liberal polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18207</td>\n",
       "      <td>1</td>\n",
       "      <td>rise up today is out!  stories of police bruta...</td>\n",
       "      <td>rise today stories police brutality from #police</td>\n",
       "      <td>rise today stories police brutality from police</td>\n",
       "      <td>[rise, today, stories, police, brutality, from...</td>\n",
       "      <td>[rise, today, stori, polic, brutal, from, polic]</td>\n",
       "      <td>[rise, today, story, police, brutality, from, ...</td>\n",
       "      <td>rise today stories police brutality from police</td>\n",
       "      <td>rise today stories police brutality from polic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20139</td>\n",
       "      <td>1</td>\n",
       "      <td>@user ouch woow! @user @user #sexy @user @user...</td>\n",
       "      <td>ouch woow #sexy</td>\n",
       "      <td>ouch woow sexy</td>\n",
       "      <td>[ouch, woow, sexy]</td>\n",
       "      <td>[ouch, woow, sexi]</td>\n",
       "      <td>[ouch, woow, sexy]</td>\n",
       "      <td>ouch woow sexy</td>\n",
       "      <td>ouch woow sexi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14894</td>\n",
       "      <td>1</td>\n",
       "      <td>\"vandals turned a jewish family's menorah into...</td>\n",
       "      <td>vandals turned jewish family menorah into swas...</td>\n",
       "      <td>vandals turned jewish family menorah into swas...</td>\n",
       "      <td>[vandals, turned, jewish, family, menorah, int...</td>\n",
       "      <td>[vandal, turn, jewish, famili, menorah, into, ...</td>\n",
       "      <td>[vandal, turned, jewish, family, menorah, into...</td>\n",
       "      <td>vandals turned jewish family menorah into swas...</td>\n",
       "      <td>vandals turned jewish family menorah into swas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>24776</td>\n",
       "      <td>1</td>\n",
       "      <td>\"the reality is that the tech industry is made...</td>\n",
       "      <td>reality that tech industry made regular people...</td>\n",
       "      <td>reality that tech industry made regular people...</td>\n",
       "      <td>[reality, that, tech, industry, made, regular,...</td>\n",
       "      <td>[realiti, that, tech, industri, made, regular,...</td>\n",
       "      <td>[reality, that, tech, industry, made, regular,...</td>\n",
       "      <td>reality that tech industry made regular people...</td>\n",
       "      <td>reality that tech industry made regular people...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  label                                              tweet  \\\n",
       "3   18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "22  18207      1  rise up today is out!  stories of police bruta...   \n",
       "33  20139      1  @user ouch woow! @user @user #sexy @user @user...   \n",
       "37  14894      1  \"vandals turned a jewish family's menorah into...   \n",
       "44  24776      1  \"the reality is that the tech industry is made...   \n",
       "\n",
       "                                           tidy_tweet  \\\n",
       "3      might libtard #libtard #sjw #liberal #politics   \n",
       "22   rise today stories police brutality from #police   \n",
       "33                                    ouch woow #sexy   \n",
       "37  vandals turned jewish family menorah into swas...   \n",
       "44  reality that tech industry made regular people...   \n",
       "\n",
       "                                        no_hash_tweet  \\\n",
       "3          might libtard libtard sjw liberal politics   \n",
       "22    rise today stories police brutality from police   \n",
       "33                                     ouch woow sexy   \n",
       "37  vandals turned jewish family menorah into swas...   \n",
       "44  reality that tech industry made regular people...   \n",
       "\n",
       "                                      tokenized_tweet  \\\n",
       "3   [might, libtard, libtard, sjw, liberal, politics]   \n",
       "22  [rise, today, stories, police, brutality, from...   \n",
       "33                                 [ouch, woow, sexy]   \n",
       "37  [vandals, turned, jewish, family, menorah, int...   \n",
       "44  [reality, that, tech, industry, made, regular,...   \n",
       "\n",
       "                                       stemmed_tokens  \\\n",
       "3        [might, libtard, libtard, sjw, liber, polit]   \n",
       "22   [rise, today, stori, polic, brutal, from, polic]   \n",
       "33                                 [ouch, woow, sexi]   \n",
       "37  [vandal, turn, jewish, famili, menorah, into, ...   \n",
       "44  [realiti, that, tech, industri, made, regular,...   \n",
       "\n",
       "                                    lemmatized_tokens  \\\n",
       "3   [might, libtard, libtard, sjw, liberal, politics]   \n",
       "22  [rise, today, story, police, brutality, from, ...   \n",
       "33                                 [ouch, woow, sexy]   \n",
       "37  [vandal, turned, jewish, family, menorah, into...   \n",
       "44  [reality, that, tech, industry, made, regular,...   \n",
       "\n",
       "                                            lem_tweet  \\\n",
       "3          might libtard libtard sjw liberal politics   \n",
       "22    rise today stories police brutality from police   \n",
       "33                                     ouch woow sexy   \n",
       "37  vandals turned jewish family menorah into swas...   \n",
       "44  reality that tech industry made regular people...   \n",
       "\n",
       "                                           stem_tweet  \n",
       "3             might libtard libtard sjw liberal polit  \n",
       "22     rise today stories police brutality from polic  \n",
       "33                                     ouch woow sexi  \n",
       "37  vandals turned jewish family menorah into swas...  \n",
       "44  reality that tech industry made regular people...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1= df[df['label']==1]\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "      <th>no_hash_tweet</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lem_tweet</th>\n",
       "      <th>stem_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29727</td>\n",
       "      <td>0</td>\n",
       "      <td>sad to see the scenes of hooligans pre #engrus...</td>\n",
       "      <td>scenes hooligans #engrus spoil #euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>[scenes, hooligans, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>[scene, hooligan, engrus, spoil, euro]</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "      <td>scenes hooligans engrus spoil euro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14466</td>\n",
       "      <td>0</td>\n",
       "      <td>#gooddyeyoung #yoyoyo  !! super happy to be ap...</td>\n",
       "      <td>#gooddyeyoung #yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happi, movement]</td>\n",
       "      <td>[gooddyeyoung, yoyoyo, super, happy, movement]</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy movement</td>\n",
       "      <td>gooddyeyoung yoyoyo super happy mov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18194</td>\n",
       "      <td>0</td>\n",
       "      <td>queen evil's bihdayð#lnic #lnicjustanevilbd...</td>\n",
       "      <td>queen evil bihday #lnic #lnicjustanevilbday #b...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>[queen, evil, bihday, lnic, lnicjustanevilbday...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "      <td>queen evil bihday lnic lnicjustanevilbday bihd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18283</td>\n",
       "      <td>1</td>\n",
       "      <td>@user you might be a libtard if... #libtard  #...</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liber, polit]</td>\n",
       "      <td>[might, libtard, libtard, sjw, liberal, politics]</td>\n",
       "      <td>might libtard libtard sjw liberal politics</td>\n",
       "      <td>might libtard libtard sjw liberal polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25845</td>\n",
       "      <td>0</td>\n",
       "      <td>what are your goals? find out here...   #smile...</td>\n",
       "      <td>what your goals find here #smile</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>[what, your, goals, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>[what, your, goal, find, here, smile]</td>\n",
       "      <td>what your goals find here smile</td>\n",
       "      <td>what your goals find here smil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet  \\\n",
       "0  29727      0  sad to see the scenes of hooligans pre #engrus...   \n",
       "1  14466      0  #gooddyeyoung #yoyoyo  !! super happy to be ap...   \n",
       "2  18194      0  queen evil's bihdayð#lnic #lnicjustanevilbd...   \n",
       "3  18283      1  @user you might be a libtard if... #libtard  #...   \n",
       "4  25845      0  what are your goals? find out here...   #smile...   \n",
       "\n",
       "                                          tidy_tweet  \\\n",
       "0               scenes hooligans #engrus spoil #euro   \n",
       "1         #gooddyeyoung #yoyoyo super happy movement   \n",
       "2  queen evil bihday #lnic #lnicjustanevilbday #b...   \n",
       "3     might libtard #libtard #sjw #liberal #politics   \n",
       "4                   what your goals find here #smile   \n",
       "\n",
       "                                       no_hash_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                     tokenized_tweet  \\\n",
       "0           [scenes, hooligans, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4             [what, your, goals, find, here, smile]   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happi, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3       [might, libtard, libtard, sjw, liber, polit]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0             [scene, hooligan, engrus, spoil, euro]   \n",
       "1     [gooddyeyoung, yoyoyo, super, happy, movement]   \n",
       "2  [queen, evil, bihday, lnic, lnicjustanevilbday...   \n",
       "3  [might, libtard, libtard, sjw, liberal, politics]   \n",
       "4              [what, your, goal, find, here, smile]   \n",
       "\n",
       "                                           lem_tweet  \\\n",
       "0                 scenes hooligans engrus spoil euro   \n",
       "1           gooddyeyoung yoyoyo super happy movement   \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...   \n",
       "3         might libtard libtard sjw liberal politics   \n",
       "4                    what your goals find here smile   \n",
       "\n",
       "                                          stem_tweet  \n",
       "0                 scenes hooligans engrus spoil euro  \n",
       "1                gooddyeyoung yoyoyo super happy mov  \n",
       "2  queen evil bihday lnic lnicjustanevilbday bihd...  \n",
       "3            might libtard libtard sjw liberal polit  \n",
       "4                     what your goals find here smil  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.lem_tweet = df.lem_tweet.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stem_tweet = df.stem_tweet.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/cleaned-reshuffled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('data/cleaned-reshuffled.csv')\n",
    "# df.drop(['Unnamed: 0'], axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# cloud_mask = np.array(Image.open(\"twitter.png\"))\n",
    "# cloud_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "df_0_words = ' '.join([text for text in df['tidy_tweet'][df['label']==0]])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=10, max_font_size=110).generate(df_0_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_words = ' '.join([text for text in df['tidy_tweet'][df['label']==1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=210, max_font_size=110).generate(df_1_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect hashtags\n",
    "def hashtag_extract(tweet):\n",
    "    hashtags = []\n",
    "    # Loop over the words in the tweet\n",
    "    for word in tweet:\n",
    "        ht = re.findall(r\"#(\\w+)\", word)\n",
    "        hashtags.append(ht)\n",
    "\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting hashtags from non racist/sexist tweets\n",
    "HT_0 = hashtag_extract(df['tidy_tweet_2'][df['label']==0])\n",
    "\n",
    "# extracting hashtags from racist/sexist tweets\n",
    "HT_1 = hashtag_extract(df['tidy_tweet_2'][df['label']==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnesting lists\n",
    "HT_0 = sum(HT_0,[])\n",
    "HT_1 = sum(HT_1,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HT_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nltk.FreqDist(HT_0)\n",
    "d = pd.DataFrame({'Hashtag': list(a.keys()),\n",
    "                  'Count': list(a.values())})\n",
    "# selecting top 10 most frequent hashtags     \n",
    "d = d.nlargest(columns=\"Count\", n = 10) \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=d, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = nltk.FreqDist(HT_1)\n",
    "e = pd.DataFrame({'Hashtag': list(b.keys()), 'Count': list(b.values())})\n",
    "# selecting top 10 most frequent hashtags\n",
    "e = e.nlargest(columns=\"Count\", n = 10)   \n",
    "plt.figure(figsize=(16,5))\n",
    "ax = sns.barplot(data=e, x= \"Hashtag\", y = \"Count\")\n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(HT_1)\n",
    "meta_freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist.plot(10,cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_freqdist = FreqDist(HT_0)\n",
    "meta_freqdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_freqdist.plot(10,cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "meta_finder = BigramCollocationFinder.from_words(df['no_hash_tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_scored = meta_finder.score_ngrams(bigram_measures.raw_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
