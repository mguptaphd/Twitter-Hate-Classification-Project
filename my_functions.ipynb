{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to View Classifier Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_predictions_dataframe (y_true, y_pred, y_pred_prob):\n",
    "    '''\n",
    "    Combines and returns actual and predicted classes in a single datafame\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    y_true: actual y value \n",
    "    \n",
    "    y_pred: predicted y value\n",
    "    \n",
    "    y_pred_prob: predicted probability for y\n",
    "\n",
    "    '''\n",
    "    pred_df = pd.DataFrame(y_pred_prob, columns = ['prob 0', 'prob 1'])\n",
    "    pred_df['predicted class'] = y_pred\n",
    "    pred_df.index = y_true.index \n",
    "    pred_df['actual class'] = y_true\n",
    "    \n",
    "    return pred_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix (y_true, y_pred):\n",
    "    '''\n",
    "    Returns simple confusion matrix with labeled index and column headings.\n",
    "    '''\n",
    "    cm = pd.DataFrame(confusion_matrix(y_true, y_pred), index = ['actual 0','actual 1'], \n",
    "          columns = ['predicted 0', 'predicted 1'])  \n",
    "        \n",
    "    return cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seaborn_confusion_matrix (y_true, y_pred):\n",
    "    '''\n",
    "    Visualizes confusion matrix in seaborn.  Figure can be saved by wrapping function in plt.savefig\n",
    "    '''\n",
    "    cm = confusion_matrix(y_true, y_pred) \n",
    "    sns.heatmap(cm, square=True, annot=True, fmt = 'g', cmap='YlGnBu', cbar=False, \n",
    "                xticklabels=['Not Hate', 'Hate Speech'], \n",
    "                yticklabels=['Not Hate', 'Hate Speech'])\n",
    "    plt.title('Confusion Matrix:')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Actual Class')\n",
    "#     plt.savefig('data/cm')\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(y_true, y_pred):\n",
    "    '''\n",
    "    Returns pre-labeled classification report\n",
    "    '''\n",
    "    report = print(metrics.classification_report(y_true, y_pred, target_names = ['not hate', 'hate speech']))\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classification_metrics (y_train, y_train_pred, y_val, y_val_pred):\n",
    "    '''\n",
    "    Returns a dictionary containing metrics for train and validation sets\n",
    "    '''\n",
    "    #prints train and validation set metrics\n",
    "    metrics_dict = {\n",
    "    'Train Accuracy' : round(metrics.accuracy_score(y_train, y_train_pred),2),\n",
    "    'Train Precision' : round(metrics.precision_score(y_train, y_train_pred),2),\n",
    "    'Train Recall' : round(metrics.recall_score(y_train, y_train_pred),2),\n",
    "    'Train F1': round(metrics.f1_score(y_train, y_train_pred),2),\n",
    "\n",
    "    'Validation Accuracy': round(metrics.accuracy_score(y_val, y_val_pred),2),\n",
    "    'Validation Precision' : round(metrics.precision_score(y_val, y_val_pred),2),\n",
    "    'Validation Recall': round(metrics.recall_score(y_val, y_val_pred),2),\n",
    "    'Validation F1': round(metrics.f1_score(y_val, y_val_pred),2)\n",
    "    }\n",
    "    \n",
    "    return metrics_dict   #  to return as a dataframe: pd.DataFrame(metrics_dict, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_threshold_and_score (y_true, y_pred_prob, threshold, RNN = False):\n",
    "    '''\n",
    "    Plots confusion matrix and calculates classification metrics based on adjusted probability threshold\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    y_true: actual y values\n",
    "    \n",
    "    y_pred_prob: predicted probabilities for y \n",
    "    \n",
    "    threshold: enter the adjusted probability threshold for classification (can be a float or integer)\n",
    "    \n",
    "    RNN: indicate as True if classifier is an RNN; default value is False\n",
    "    '''\n",
    "    #initializes a list to store adjusted y predictions\n",
    "    y_pred_adjusted = []\n",
    "\n",
    "    #for loop assigns a predicted class for y based on the threshhold value that was entered \n",
    "    if RNN == False:\n",
    "\n",
    "        for item in y_pred_prob:\n",
    "            if item[0] <= threshold:\n",
    "                y_pred_adjusted.append(1)\n",
    "            else:\n",
    "                y_pred_adjusted.append(0)\n",
    "    else:\n",
    "\n",
    "          for item in y_pred_prob:\n",
    "            if item[0] >= threshold:\n",
    "                y_pred_adjusted.append(1)\n",
    "            else:\n",
    "                y_pred_adjusted.append(0)\n",
    "    \n",
    "    #print metrics according to adjusted threshold\n",
    "    print('Adjusted Accuracy: ' + str(metrics.accuracy_score(y_true, y_pred_adjusted)))\n",
    "    print('Adjusted Precision: ' + str(metrics.precision_score(y_true, y_pred_adjusted)))\n",
    "    print('Adjusted Recall: ' + str(metrics.recall_score(y_true, y_pred_adjusted)))\n",
    "    print('Adjusted F1 Score: ' + str(metrics.f1_score(y_true, y_pred_adjusted)))\n",
    "    print('\\n')\n",
    "    \n",
    "    # calls confusion matrix function \n",
    "    cm = seaborn_confusion_matrix(y_true, y_pred_adjusted)\n",
    "    \n",
    "    #return list of adjusted y predictions and confusion matrix\n",
    "    return y_pred_adjusted, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Quickly Compare Different Vectorization Methods and Class Imbalance Corrections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Vectorizer Functions\n",
    "##### Used to examine the performance of a model with a single vectorizer in detail, after doing initial comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer):\n",
    "    \n",
    "    '''\n",
    "    Apply the specified text vectorizer,make predictions and calculate scores with specified classifier.\n",
    "\n",
    "    No explicit correction for class imbalances is conducted in this function, \n",
    "    but up or downsampled X_train and y_train variables can be passed as arguments\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_train: enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    X_val_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_val:  enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    vectorizer: indicate text vectorization method; uses default parameters if none are specified\n",
    "\n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "\n",
    "    '''\n",
    "    \n",
    "    X_train_transformed = vectorizer.fit_transform(X_train_col)\n",
    "    X_val_transformed = vectorizer.transform(X_val_col)\n",
    "            \n",
    "    fitted_classifier = classifier.fit(X_train_transformed, y_train.values.ravel())\n",
    "    \n",
    "    y_train_pred = classifier.predict(X_train_transformed)\n",
    "    y_val_pred = classifier.predict(X_val_transformed)\n",
    "    \n",
    "    y_train_prob = classifier.predict_proba(X_train_transformed)\n",
    "    y_val_prob = classifier.predict_proba(X_val_transformed)\n",
    "     \n",
    "    metrics_dict = compare_classification_metrics(y_train, y_train_pred, y_val, y_val_pred)\n",
    "        \n",
    "    pred_df = compare_predictions_dataframe(y_val, y_val_pred, y_val_prob)\n",
    "                     \n",
    "    return fitted_classifier, X_val_transformed, pd.DataFrame(y_train_pred), pd.DataFrame(y_val_pred), y_val_prob, metrics_dict, pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer, sample_class = 'not majority'):\n",
    "    '''\n",
    "    Returns five values: Transformed X_val, classification metrics dictionary, validation confusion matrix, \n",
    "    predicted values for y_val, predicted probabilities for y_val, predictions dataframe\n",
    "     \n",
    "    Applies the specified text vectorizer, use SMOTE to rebalance class sizes, \n",
    "    and then make predictions and calculate scores for specified classifier\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_train: enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    X_val_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_val_col:  enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    vectorizer: indicate text vectorization method; uses default parameters if none are specified\n",
    "\n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    sample_class: default is 'not majority'; other choices include: 'minority', 'not minority', \n",
    "    'not majority' or 'all'. Can also enter a float from 0 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    X_train_transformed = vectorizer.fit_transform(X_train_col)\n",
    "    X_val_transformed = vectorizer.transform(X_val_col)\n",
    "    \n",
    "    smote = SMOTE(random_state=1, sampling_strategy = sample_class)\n",
    "    \n",
    "    X_train2, y_train2 = smote.fit_resample(X_train_transformed, y_train)\n",
    "    \n",
    "    model = classifier.fit(X_train2, y_train2)\n",
    "    \n",
    "#     pipe = make_pipeline(smote, classifier) \n",
    "    \n",
    "#     model = pipe.fit(X_train_transformed, y_train.values.ravel())\n",
    "\n",
    "    y_train_pred = classifier.predict(X_train2)\n",
    "    y_val_pred = classifier.predict (X_val_transformed)\n",
    "    \n",
    "    y_train_prob = classifier.predict_proba(X_train2)\n",
    "    y_val_prob = classifier.predict_proba(X_val_transformed)\n",
    "    \n",
    "#     y_train_pred = model.predict(X_train_transformed)\n",
    "#     y_val_pred = model.predict (X_val_transformed)\n",
    "    \n",
    "#     y_train_prob = model.predict_proba(X_train_transformed)\n",
    "#     y_val_prob = model.predict_proba(X_val_transformed)\n",
    "    \n",
    "    # print scores  \n",
    "    metrics_dict = compare_classification_metrics(y_train2, y_train_pred, y_val, y_val_pred)\n",
    "        \n",
    "    pred_df = compare_predictions_dataframe(y_val, y_val_pred, y_val_prob)\n",
    "                     \n",
    "    return model, X_val_transformed, pd.DataFrame(y_train_pred), pd.DataFrame(y_val_pred), y_val_prob, metrics_dict, pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer):\n",
    "    \n",
    "    '''\n",
    "    Returns five values: Transformed X_val, classification metrics dictionary, validation confusion matrix, \n",
    "    predicted values for y_val, predicted probabilities for y_val, predictions dataframe\n",
    "     \n",
    "    Oversamples from the minoriy class (label = 1) until it is the size of the minority class (label = 0)\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_train: enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    X_val_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_val_col:  enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    vectorizer: indicate text vectorization method; uses default parameters if none are specified\n",
    "\n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "\n",
    "    '''\n",
    "    #upsample data \n",
    "    X_train_col_up, y_train_up = upsample_training_data(X_train_col, y_train)\n",
    "    \n",
    "    # perform vectorization\n",
    "    X_train_up_transformed = vectorizer.fit_transform(X_train_col_up.values.ravel())\n",
    "    X_val_transformed = vectorizer.transform(X_val_col)\n",
    "                \n",
    "    fitted_classifier = classifier.fit(X_train_up_transformed, y_train_up.values.ravel())\n",
    "    \n",
    "    #train and validate classifier\n",
    "    y_train_up_pred = classifier.predict(X_train_up_transformed)\n",
    "    y_val_pred = classifier.predict(X_val_transformed)\n",
    "    \n",
    "    y_train_up_prob = classifier.predict_proba(X_train_up_transformed)\n",
    "    y_val_prob = classifier.predict_proba(X_val_transformed)\n",
    "    \n",
    "    # print scores  \n",
    "    metrics_dict = compare_classification_metrics(y_train_up, y_train_up_pred, y_val, y_val_pred)\n",
    "    \n",
    "#     conf_matrix = print_confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    pred_df = compare_predictions_dataframe(y_val, y_val_pred, y_val_prob)\n",
    "                     \n",
    "    return fitted_classifier, X_val_transformed, pd.DataFrame(y_train_up_pred), pd.DataFrame(y_val_pred), y_val_prob, metrics_dict, pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer):\n",
    " \n",
    "    '''\n",
    "    Downsamples from the majority class (label = 0) until it is the size of the minority class (label = 1)\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_train: enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    X_val_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_val_col:  enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    vectorizer: indicate text vectorization method; uses default parameters if none are specified\n",
    "\n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "\n",
    "    '''\n",
    "    #downsample data \n",
    "    X_train_col_down, y_train_down = downsample_training_data(X_train_col, y_train)\n",
    "\n",
    "    #perform vectorization\n",
    "    X_train_down_transformed = vectorizer.fit_transform(X_train_col_down.values.ravel())\n",
    "    X_val_transformed = vectorizer.transform(X_val_col.values.ravel())\n",
    "                \n",
    "    fitted_classifier = classifier.fit(X_train_down_transformed, y_train_down.values.ravel())\n",
    "    \n",
    "    #train and validate classifier\n",
    "    y_train_down_pred = classifier.predict(X_train_down_transformed)\n",
    "    y_val_pred = classifier.predict(X_val_transformed)\n",
    "    \n",
    "    y_train_down_prob = classifier.predict_proba(X_train_down_transformed)\n",
    "    y_val_prob = classifier.predict_proba(X_val_transformed)\n",
    "    \n",
    "    # print scores  \n",
    "    metrics_dict = compare_classification_metrics(y_train_down, y_train_down_pred, y_val, y_val_pred)\n",
    "    \n",
    "    # conf_matrix = print_confusion_matrix(y_val, y_val_pred.ravel())\n",
    "    \n",
    "    pred_df = compare_predictions_dataframe(y_val, y_val_pred, y_val_pred_prob)\n",
    "                     \n",
    "    return fitted_classifier, X_val_transformed, pd.DataFrame(y_train_down_pred), \n",
    "    pd.DataFrame(y_val_pred), y_val_prob, metrics_dict, pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Comparison Functions\n",
    "\n",
    "##### Use to compare the performance of a model with multiple vectorization strategies at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list):\n",
    "    '''\n",
    "    Compares classification model performance using different text vectorizers,\n",
    "    (declared in 'vectorization list') outside the function.  \n",
    "        \n",
    "    Parameters:\n",
    "    \n",
    "    X_train_col: cleaned text column in training set\n",
    "    \n",
    "    y_train: target variable in training set\n",
    "    \n",
    "    X_val_col: cleaned text column in validation set\n",
    "    \n",
    "    y_val: target variable in validation set \n",
    "    \n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    vectorization_list: list of tuples specficifying each name and vectorization method to be used\n",
    "\n",
    "    '''\n",
    "    metrics_dict2 = {}\n",
    "                \n",
    "    for name, vectorizer in vectorization_list:\n",
    "                \n",
    "        X_train_transformed = vectorizer.fit_transform(X_train_col)\n",
    "        X_val_transformed = vectorizer.transform (X_val_col)\n",
    "\n",
    "        classifier.fit(X_train_transformed, y_train.values.ravel())\n",
    "    \n",
    "        y_train_pred = classifier.predict (X_train_transformed)\n",
    "        y_val_pred = classifier.predict (X_val_transformed)   \n",
    "        \n",
    "        scores = compare_classification_metrics (y_train, y_train_pred, y_val, y_val_pred)\n",
    "        \n",
    "        metrics_dict2[name] = scores\n",
    "        \n",
    "    return pd.DataFrame(metrics_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, \n",
    "                                      classifier, vectorization_list, sample_class = 'not majority'):\n",
    "  \n",
    "    '''\n",
    "    Compares the performance of a single classifier using different text vectorization methods.\n",
    "    \n",
    "    Uses SMOTE to correct for class imbalance before fitting classifier. Sampling methods are indicated below.\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    X_train_col: cleaned text column in training set\n",
    "    \n",
    "    y_train: target variable in training set\n",
    "    \n",
    "    X_val_col: cleaned text column in validation set\n",
    "    \n",
    "    y_val: target variable in validation set \n",
    "    \n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    vectorization_list: list of tuples specficifying each name and vectorization method to be used\n",
    "    \n",
    "    sample_class: default is 'not majority'; other choices include: 'minority', 'not minority', \n",
    "    'not majority' or 'all'. Can also enter a float between 0 to 1\n",
    "\n",
    "    '''   \n",
    "    metrics_dict2 = {}\n",
    "        \n",
    "    for name, vectorizer in vectorization_list:\n",
    "              \n",
    "        X_train_transformed = vectorizer.fit_transform(X_train_col)\n",
    "        X_val_transformed = vectorizer.transform (X_val_col)\n",
    "        \n",
    "        smote = SMOTE(random_state=1, sampling_strategy = sample_class)\n",
    "        \n",
    "        smote.fit(X_train_transformed)\n",
    "    \n",
    "        pipe = make_pipeline(smote, classifier) \n",
    "    \n",
    "        model = pipe.fit(X_train_transformed, y_train.values.ravel())\n",
    "    \n",
    "        y_train_pred = model.predict(X_train_transformed)\n",
    "        y_val_pred = model.predict (X_val_transformed)\n",
    "        \n",
    "        y_train_pred_prob = classifier.predict_proba(X_train_transformed)\n",
    "        y_val_pred_prob = classifier.predict_proba(X_val_transformed)\n",
    "    \n",
    "        scores = compare_classification_metrics (y_train, y_train_pred, y_val, y_val_pred)\n",
    "        \n",
    "        metrics_dict2[name] = scores\n",
    "        \n",
    "    return pd.DataFrame(metrics_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list):\n",
    "    \n",
    "    '''\n",
    "    Oversamples from the minority class (label = 1) until it is the size of the minority class (label = 0)\n",
    "    \n",
    "    Vectorization list should be identified as a tuple outside the function\n",
    "    \n",
    "    Returns a pandas dataframe with metrics from all tests\n",
    "        \n",
    "    Parameters:\n",
    "    \n",
    "    X_train_col: cleaned text column in training set\n",
    "    \n",
    "    y_train: target variable in training set\n",
    "    \n",
    "    X_val_col: cleaned text column in validation set\n",
    "    \n",
    "    y_val: target variable in validation set \n",
    "    \n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    vectorization_list: list of tuples specficifying each name and vectorization method to be used\n",
    "\n",
    "    '''\n",
    "    X_train_col_up, y_train_up = upsample_training_data(X_train_col, y_train)\n",
    "    \n",
    "    metrics_dict2 = {}\n",
    "\n",
    "    for name, vectorizer in vectorization_list:\n",
    "    \n",
    "        # perform vectorization\n",
    "        X_train_up_transformed = vectorizer.fit_transform(X_train_col_up.values.ravel())\n",
    "        X_val_transformed = vectorizer.transform(X_val_col)\n",
    "\n",
    "        classifier.fit(X_train_up_transformed, y_train_up.values.ravel())\n",
    "\n",
    "        #train and validate classifier\n",
    "        y_train_up_pred = classifier.predict(X_train_up_transformed)\n",
    "        y_val_pred = classifier.predict(X_val_transformed)\n",
    "\n",
    "        y_train_up_pred_prob = classifier.predict_proba(X_train_up_transformed)\n",
    "        y_val_pred_prob = classifier.predict_proba(X_val_transformed)\n",
    "\n",
    "        scores = compare_classification_metrics (y_train_up, y_train_up_pred, y_val, y_val_pred)\n",
    "\n",
    "        metrics_dict2[name] = scores\n",
    "        \n",
    "    return pd.DataFrame(metrics_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list):\n",
    " \n",
    "    '''\n",
    "    downsamples from the majority class (label = 0) until it is the size of the minority class (label = 1)\n",
    "\n",
    "    Vectorization list should be identified as a tuple outside the function\n",
    "    \n",
    "    Returns a pandas dataframe with metrics from all tests\n",
    "        \n",
    "    Parameters:\n",
    "    \n",
    "    X_train_col: cleaned text column in training set\n",
    "    \n",
    "    y_train: target variable in training set\n",
    "    \n",
    "    X_val_col: cleaned text column in validation set\n",
    "    \n",
    "    y_val: target variable in validation set \n",
    "    \n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    vectorization_list: list of tuples specficifying each name and vectorization method to be used\n",
    "\n",
    "    '''\n",
    "   #downsample data \n",
    "    X_train_col_down, y_train_down = downsample_training_data(X_train_col, y_train)\n",
    "    \n",
    "    metrics_dict2 = {}\n",
    "\n",
    "    for name, vectorizer in vectorization_list:\n",
    "\n",
    "        #perform vectorization\n",
    "        X_train_down_transformed = vectorizer.fit_transform(X_train_col_down.values.ravel())\n",
    "        X_val_transformed = vectorizer.transform(X_val_col.values.ravel())\n",
    "\n",
    "        classifier.fit(X_train_down_transformed, y_train_down.values.ravel())\n",
    "\n",
    "        #train and validate classifier\n",
    "        y_train_down_pred = classifier.predict(X_train_down_transformed)\n",
    "        y_val_pred = classifier.predict(X_val_transformed)\n",
    "\n",
    "        y_train_down_pred_prob = classifier.predict_proba(X_train_down_transformed)\n",
    "        y_val_pred_prob = classifier.predict_proba(X_val_transformed)\n",
    "\n",
    "        scores = compare_classification_metrics (y_train_down, y_train_down_pred, y_val, y_val_pred)\n",
    "\n",
    "        metrics_dict2[name] = scores\n",
    "        \n",
    "    return pd.DataFrame(metrics_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_single_vectorization(X_train_col, y_train, X_val_col, y_val, classifier, \n",
    "                                 vectorizer, sampling = None, sample_class = 'not majority'):\n",
    "    \n",
    "    '''\n",
    "    Apply the specified text vectorizer and and then make predictions and calculate scores for specified classifier\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    X_train_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_train: enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    X_val_col: specify cleaned text column to be used for vectorization and predictions\n",
    "\n",
    "    y_val_col:  enter as a one-dimensional vector; function transforms into an array\n",
    "\n",
    "    vectorizer: indicate text vectorization method; uses default parameters if none are specified\n",
    "\n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    sample_class: default is 'not majority'\n",
    "\n",
    "    '''\n",
    "    \n",
    "    if sampling is None:\n",
    "        results = single_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer)\n",
    "    \n",
    "    elif sampling is 'smote':\n",
    "        results = smote_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer, sample_class)\n",
    "\n",
    "    elif sampling is 'upsample':\n",
    "        results = upsample_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer)\n",
    "                        \n",
    "    elif sampling is 'downsample':\n",
    "        results = downsample_vector_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorizer)\n",
    "        \n",
    "    else:\n",
    "        results = print('Sampling method does not exist. Indicate: smote, upsample or downsample')\n",
    "                \n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_compare_vectorizations(X_train_col, y_train, X_val_col, y_val, classifier, \n",
    "                                   vectorization_list, sampling = None, sample_class = 'not majority'):\n",
    "    '''\n",
    "    Returns a dataframe with train and validation metrics for multiple vectorizers.\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    X_train_col: cleaned text column in training set\n",
    "    \n",
    "    y_train: target variable in training set\n",
    "    \n",
    "    X_val_col: cleaned text column in validation set\n",
    "    \n",
    "    y_val: target variable in validation set \n",
    "    \n",
    "    classifier: name of classifier; uses default parameters if none are specified\n",
    "    \n",
    "    vectorization_list: list of tuples specficifying each name and vectorization method to be used\n",
    "\n",
    "    sampling: optional parameter; choices\n",
    "    '''\n",
    "    \n",
    "    if sampling is None:\n",
    "        results = compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list)\n",
    "        \n",
    "    elif sampling is 'smote':\n",
    "        results = smote_compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list, sample_class)\n",
    "                        \n",
    "    elif sampling is 'upsample':\n",
    "        results = upsample_compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list)\n",
    "        \n",
    "    elif sampling is 'downsample':\n",
    "        results = downsample_compare_vectorization_model(X_train_col, y_train, X_val_col, y_val, classifier, vectorization_list)\n",
    "\n",
    "    else:\n",
    "        results = print('Sampling method does not exist. Indicate: smote, upsample or downsample')\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling and Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_training_data(X_train_col, y_train):\n",
    "    \n",
    "    '''\n",
    "    draws samples from the minoriy class (label = 1) until it is the size of the minority class (label = 0)\n",
    "\n",
    "    returns a single upsampled dataframe (with both X_train and y_train in one dataframe)\n",
    "\n",
    "    '''\n",
    "    training_data = pd.DataFrame(X_train_col)\n",
    "    training_data['label']= y_train\n",
    "\n",
    "    train_0 = training_data[training_data.label==0]\n",
    "    train_1 = training_data[training_data.label==1]\n",
    "\n",
    "    train_1_up = resample(train_1, \n",
    "          replace=True,    \n",
    "          n_samples=len(train_0),   \n",
    "          random_state=10)\n",
    "\n",
    "    train_upsampled = pd.concat([train_1_up, train_0])\n",
    "    \n",
    "    X_train_col_up = train_upsampled.drop(['label'], axis = 1)\n",
    "    y_train_up = train_upsampled.label\n",
    "    \n",
    "    return X_train_col_up, y_train_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_training_data(X_train_col, y_train):\n",
    "    \n",
    "    '''\n",
    "    draws samples from the majority class (label = 0) until it is the size of the minority class (label = 1)\n",
    "\n",
    "    returns a single downsampled dataframe (with both X_train and y_train in one dataframe)\n",
    "\n",
    "    '''\n",
    "    training_data = pd.DataFrame(X_train_col)\n",
    "    training_data['label']= y_train\n",
    "    \n",
    "    train_0 = training_data[training_data.label==0]\n",
    "    train_1 = training_data[training_data.label==1]\n",
    "\n",
    "    train_0_down = resample(train_0, \n",
    "          replace=True,    \n",
    "          n_samples=len(train_1),   \n",
    "          random_state=10)\n",
    "\n",
    "    train_downsampled = pd.concat([train_0_down, train_1])\n",
    "    \n",
    "    X_train_col_down = train_downsampled.drop(['label'], axis = 1)\n",
    "    y_train_down = train_downsampled.label\n",
    "    \n",
    "    return X_train_col_down, y_train_down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Word Embeddings/Deep Learning (Word2Vec, Glove, RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word_vectors(sentence, model_name, dimsize):\n",
    "    '''\n",
    "    Calculate the mean word embedding for every sentence in the dataset.\n",
    "        \n",
    "    Parameters:\n",
    "    \n",
    "    wordlist: list of the list of words in each sentence\n",
    "    \n",
    "    size: size of hidden layer\n",
    "    \n",
    "    model_name: name of wv2 model\n",
    "    \n",
    "    '''\n",
    "\n",
    "    sumvec = np.zeros(shape = (1, dimsize))\n",
    "    wordcnt = 0\n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in model_name:\n",
    "            sumvec += model_name[word]\n",
    "            wordcnt +=1\n",
    "    \n",
    "    if wordcnt == 0:\n",
    "        return sumvec\n",
    "    \n",
    "    else:\n",
    "        return sumvec / wordcnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_embedding_compare_classification(X_train, y_train, X_val, y_val, classifier_list, \n",
    "                                          sampling = None, sample_class = 'not majority'):\n",
    "    '''\n",
    "    Function to allow for quick comparison of word2vec and glove word embeddings with each of the classifiers.\n",
    "        \n",
    "    Returns a pandas dataframe with the metrics for each classifier\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    X_train, X_val: mean train and validation word embeddings from word2vec or glove\n",
    "    \n",
    "    y_train, y_val: actual y values for train and validation sets\n",
    "    \n",
    "    classifier_list: classifiers for comparison. Should be declared outside the function in a tuple 'classifier_list'\n",
    "\n",
    "    sampling: default is none; options include 'upsample', 'downsample', 'smote'\n",
    "    \n",
    "    sample_class: can identify when 'smote' is selected for sampling in previous parameter; default is 'not majority'\n",
    "    '''  \n",
    "   \n",
    "    metrics_dict = {}\n",
    "    \n",
    "    for name, classifier in classifier_list:\n",
    "\n",
    "        if sampling is 'upsample':\n",
    "        \n",
    "            X_train, y_train = upsample_training_data(X_train, y_train)\n",
    "            model = classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "        elif sampling is 'downsample':\n",
    "\n",
    "            X_train, y_train = downsample_training_data(X_train, y_train)\n",
    "            model = classifier.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "        elif sampling is 'smote':\n",
    "    \n",
    "            smote = SMOTE(random_state=1, sampling_strategy = sample_class)\n",
    "            pipe = make_pipeline(smote, classifier) \n",
    "            model = pipe.fit(X_train, y_train.values.ravel())\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            model = classifier.fit(X_train, y_train)\n",
    "    \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "    \n",
    "        metrics_dict[name] = compare_classification_metrics(y_train, y_train_pred, y_val, y_val_pred)\n",
    "    \n",
    "    return pd.DataFrame(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_smote_w2v_model(X_train_w2v, y_train, X_val_w2v, y_val, classifier):\n",
    "    \n",
    "    pca = decomposition.PCA(n_components=10)\n",
    "    \n",
    "    smote = SMOTE(random_state=10, sampling_strategy='not majority')\n",
    "        \n",
    "    pipe = make_pipeline(pca, smote, classifier) \n",
    "    \n",
    "    model = pipe.fit(X_train_w2v, y_train)\n",
    "    \n",
    "    y_train_pred = model.predict(X_train_w2v_2)\n",
    "    y_val_pred = model.predict (X_val_w2v_2)\n",
    "    \n",
    "    metrics_dict = compare_classification_metrics(y_train, y_train_pred, y_val, y_val_pred)\n",
    "    \n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss (model_title, model_name, y_acc, y_loss):\n",
    "    '''\n",
    "    Plots accuracy and loss for RNN classifier\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    model_title: enter as a string, to be included in graph title\n",
    "    \n",
    "    model_name: enter variable name for model\n",
    "    \n",
    "    '''\n",
    "    # Create Figure and Subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,4), sharex = True)\n",
    "\n",
    "    # Plot\n",
    "    ax1.plot(model_name.history.history['acc'], color='blue', label='train accuracy')\n",
    "    ax1.plot(model_name.history.history['val_acc'], color='green', label='val accuracy')\n",
    "\n",
    "    ax2.plot(model_name.history.history['loss'], color='blue', label='train loss')\n",
    "    ax2.plot(model_name.history.history['val_loss'], color = 'green', label= 'val_loss')\n",
    "\n",
    "    # Title, X and Y labels\n",
    "    ax1.set_title('Accuracy for {}'.format(model_title)); ax2.set_title('Loss for {}'.format(model_title))\n",
    "    ax1.set_xlabel('Epochs');  ax2.set_xlabel('Epochs')  \n",
    "    ax1.set_ylabel('Accuracy');  ax2.set_ylabel('Loss')  \n",
    "    ax1.set_ylim(y_acc);  ax2.set_ylim(y_loss)  \n",
    "\n",
    "    ax1.legend(); ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig('results/RNN/figures/Accuracy_Loss_{}'.format(model_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    '''\n",
    "    Plots the word embeddings created by the word2vec model\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    model: variable name for word2vec model\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=250, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "#tnse_plot(model_w2v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
